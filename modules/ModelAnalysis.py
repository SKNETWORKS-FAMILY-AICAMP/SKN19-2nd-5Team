"""

ëª¨ë¸ ë¶„ì„ ì‹œê°í™” ëª¨ë“ˆ

- fitëœ ëª¨ë¸ì„ ì¸ìë¡œ ë°›ì•„ì„œ ìˆ˜í–‰

"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import streamlit as st

import torch

from modules.Models import compute_risk_score_sigmoid


def predict_event_probabilities(
    input_df: pd.DataFrame,
    model,
    device: torch.device,
    dp=None,
    time_column: str = "Survival months_bin_3m",
    target_column: str = "target_label",
) -> pd.DataFrame:
    """
    1í–‰ ì…ë ¥ ë°ì´í„°ë¥¼ ë°›ì•„ ì „ì²˜ë¦¬ í›„, ëª¨ë¸ë¡œ CIF ì „ì²´ ì˜ˆì¸¡ (ë§ˆì§€ë§‰ ì‹œê°„ bin ì œê±°)

    Args:
        input_df: 1í–‰ì§œë¦¬ DataFrame
        dp: DataPreprocessing ì¸ìŠ¤í„´ìŠ¤
        model: í•™ìŠµëœ PyTorch ëª¨ë¸
        device: 'cpu' ë˜ëŠ” 'cuda'
        time_column: ì‹œê°„ ì»¬ëŸ¼ëª…
        target_column: íƒ€ê²Ÿ ì»¬ëŸ¼ëª…

    Returns:
        pd.DataFrame: ì‚¬ê±´ë³„ Ã— ì‹œê°„ë³„ CIF (ë§ˆì§€ë§‰ ì‹œê°„ bin ì œê±°)
    """
    if dp is not None:
        processed_df = dp.run(input_df)
    else:
        processed_df = input_df

    drop_cols = [
        col for col in [time_column, target_column] if col in processed_df.columns
    ]
    features_df = processed_df.drop(columns=drop_cols)

    x = torch.tensor(features_df.values.astype(float), dtype=torch.float32).to(device)

    model.eval()
    with torch.no_grad():
        _, pmf, cif = model(x)  # cif: (1, num_events, time_bins)

    cif = cif[:, :, :-1]  # shape: (1, num_events, time_bins-1)

    num_events, num_time = cif.shape[1], cif.shape[2]
    cif_array = cif[0].cpu().numpy()  # (num_events, time_bins-1)

    time_points = [f"Time_{t}" for t in range(num_time)]
    columns = pd.MultiIndex.from_product(
        [[f"Event_{i}" for i in range(num_events)], time_points],
        names=["Event", "Time"],
    )

    result_df = pd.DataFrame(cif_array.flatten()[None, :], columns=columns)

    return result_df


def visualize_single_prediction(
    input_df,
    model,
    device,
    time_column="Survival months_bin_3m",
    target_column="target_label",
    dp=None,
    event_weights=None,
    time_lambda=0.05,
):
    """
    ë‹¨ì¼ ì…ë ¥ ë°ì´í„°(1í–‰ DataFrame)ì— ëŒ€í•´ PMFì™€ CIFë¥¼ ì‹œê°í™”
    ë§ˆì§€ë§‰ ì‹œê°„ bin(dummy)ì€ ì œê±°ë¨
    """

    if dp is not None:
        processed_df = dp.run(input_df)
    else:
        processed_df = input_df

    drop_cols = [
        col for col in [time_column, target_column] if col in processed_df.columns
    ]
    features_df = processed_df.drop(columns=drop_cols)

    x = torch.tensor(features_df.values.astype(float), dtype=torch.float32).to(device)

    model.eval()
    with torch.no_grad():
        _, pmf, cif = model(x)  # (1, num_events, time_bins)

    pmf = pmf[:, :, :-1]
    cif = cif[:, :, :-1]
    _, num_events, time_bins = cif.shape
    time_points = list(range(time_bins))

    fig_pmf, ax_pmf = plt.subplots(figsize=(8, 4))
    for k in range(num_events):
        ax_pmf.plot(time_points, pmf[0, k].cpu().numpy().flatten(), label=f"Event {k}")
    ax_pmf.set_xlabel("Time bins")
    ax_pmf.set_ylabel("Probability (PMF)")
    ax_pmf.set_title("PMF (Probability Mass Function)")
    ax_pmf.legend()
    ax_pmf.grid(True)
    ax_pmf.set_xlim(0, 90)
    ax_pmf.set_ylim(0, 0.2)
    st.pyplot(fig_pmf)

    fig_cif, ax_cif = plt.subplots(figsize=(8, 4))
    for k in range(num_events):
        ax_cif.plot(time_points, cif[0, k].cpu().numpy().flatten(), label=f"Event {k}")
    ax_cif.set_xlabel("Time bins")
    ax_cif.set_ylabel("Cumulative Probability (CIF)")
    ax_cif.set_title("CIF (Cumulative Incidence Function)")
    ax_cif.legend()
    ax_cif.grid(True)
    ax_cif.set_xlim(0, 90)
    ax_cif.set_ylim(0, 1)
    st.pyplot(fig_cif)

    cif_np = cif[0].cpu().numpy()  # (num_events, time_bins)
    num_events, time_bins = cif_np.shape

    survival_probs = []
    pred_time = None

    for t in range(time_bins):
        surv = 1 - np.sum(cif_np[:, t])  # ğŸ”¹ joint survival from CIF
        survival_probs.append(surv)

        if surv <= 0.9 and pred_time is None:
            pred_time = t

    if pred_time is None:
        pred_time = time_bins - 1

    fig_surv, ax_surv = plt.subplots(figsize=(8, 4))
    ax_surv.plot(time_points, survival_probs, color="black", linewidth=2)
    ax_surv.set_xlabel("Time bins")
    ax_surv.set_ylabel("Survival Probability S(t)")
    ax_surv.set_title("Survival Curve (No Event Occurrence Probability)")
    ax_surv.grid(True)
    ax_surv.set_xlim(0, 90)
    ax_surv.set_ylim(0, 1)
    st.pyplot(fig_surv)

    risk_score = compute_risk_score_sigmoid(
        pmf, time_lambda=time_lambda, event_weights=event_weights
    )
    st.subheader("âš ï¸ ìœ„í—˜ ì ìˆ˜ (Risk Score)")
    st.write(f"{risk_score.item():.2f} / 100")

    return pred_time


def dataset_to_dataframe(ds):
    data_list = []
    for x, t, e in ds:  # Datasetì´ (x, t, e) ë°˜í™˜
        # xê°€ Tensorë¼ë©´ numpyë¡œ ë³€í™˜
        if isinstance(x, torch.Tensor):
            x = x.detach().cpu().numpy()
        if isinstance(t, torch.Tensor):
            t = t.item()  # ë‹¨ì¼ ê°’ì¼ ê²½ìš°
        if isinstance(e, torch.Tensor):
            e = e.item()  # ë‹¨ì¼ ê°’ì¼ ê²½ìš°

        row = list(x) + [t, e]  # features + time + event
        data_list.append(row)

    # ì»¬ëŸ¼ ì´ë¦„ ìƒì„±
    num_features = len(data_list[0]) - 2
    columns = [f"feature_{i}" for i in range(num_features)] + ["time", "event"]

    df = pd.DataFrame(data_list, columns=columns)
    return df


def compute_survival_metrics(pmf: torch.Tensor):
    """
    DeepHit ëª¨ë¸ ì¶œë ¥(PMF)ë¡œë¶€í„° ì£¼ìš” ìƒì¡´ ì§€í‘œ ê³„ì‚°

    Args:
        pmf (torch.Tensor): ì‚¬ê±´ë³„ ì‹œê°„ëŒ€ í™•ë¥  ë¶„í¬ (B, E, T)
            - B: batch_size
            - E: num_events
            - T: time_bins

    Returns:
        dict: {
            'survival': (B, T) ìƒì¡´í™•ë¥ ,
            'risk_score': (B,) ì‚¬ê±´ë°œìƒ ìœ„í—˜ë„,
            'expected_time': (B,) ê¸°ëŒ€ ìƒì¡´ì‹œê°„
        }
    """
    # ----- CIF (ëˆ„ì  ì‚¬ê±´ í™•ë¥ ) -----
    cif = torch.cumsum(pmf, dim=2)  # (B, E, T)

    # cif: (B, E, T) - cumulative incidence function
    # pmf: (B, E, T) - ì‚¬ê±´ ë°œìƒ í™•ë¥ 

    # ----- ìƒì¡´ í™•ë¥  (ë…ë¦½ ì‚¬ê±´ ê°€ì •) -----
    survival = torch.prod(1 - cif, dim=1)  # (B, T)

    # ----- ìœ„í—˜ë„ (ì „ì²´ ì‚¬ê±´ ë°œìƒ í™•ë¥  í•©) -----
    risk_score = pmf.sum(dim=(1, 2))  # (B,)

    # ----- ê¸°ëŒ€ ìƒì¡´ ì‹œê°„ -----
    time_index = torch.arange(
        1, pmf.shape[2] + 1, device=pmf.device
    ).float()  # [1, 2, ..., T]
    expected_time = (survival * time_index).sum(dim=1)  # (B,)

    return {
        "survival": survival,
        "risk_score": risk_score,
        "expected_time": expected_time,
    }


def clean_encoding_map(encoding_map, convert_values_to_str=True):
    cleaned_map = {}
    for col, mapping in encoding_map.items():
        # mappingì´ dictì¸ì§€ í™•ì¸
        if not isinstance(mapping, dict):
            continue

        new_mapping = {}
        for k, v in mapping.items():
            # np.int64, np.float64 ë“± ì œê±°
            if hasattr(k, "item"):
                k = k.item()
            if convert_values_to_str:
                v = str(v)
            elif hasattr(v, "item"):
                v = v.item()
            new_mapping[k] = v
        cleaned_map[col] = new_mapping
    return cleaned_map

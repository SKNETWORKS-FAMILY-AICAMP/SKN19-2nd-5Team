{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8137a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lifelines in /opt/anaconda3/envs/nlp/lib/python3.9/site-packages (0.30.0)\n",
      "Requirement already satisfied: numpy>=1.14.0 in /opt/anaconda3/envs/nlp/lib/python3.9/site-packages (from lifelines) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.7.0 in /opt/anaconda3/envs/nlp/lib/python3.9/site-packages (from lifelines) (1.13.1)\n",
      "Requirement already satisfied: pandas>=2.1 in /opt/anaconda3/envs/nlp/lib/python3.9/site-packages (from lifelines) (2.2.3)\n",
      "Requirement already satisfied: matplotlib>=3.0 in /opt/anaconda3/envs/nlp/lib/python3.9/site-packages (from lifelines) (3.9.2)\n",
      "Requirement already satisfied: autograd>=1.5 in /opt/anaconda3/envs/nlp/lib/python3.9/site-packages (from lifelines) (1.8.0)\n",
      "Requirement already satisfied: autograd-gamma>=0.3 in /opt/anaconda3/envs/nlp/lib/python3.9/site-packages (from lifelines) (0.5.0)\n",
      "Requirement already satisfied: formulaic>=0.2.2 in /opt/anaconda3/envs/nlp/lib/python3.9/site-packages (from lifelines) (1.2.1)\n",
      "Requirement already satisfied: interface-meta>=1.2.0 in /opt/anaconda3/envs/nlp/lib/python3.9/site-packages (from formulaic>=0.2.2->lifelines) (1.3.0)\n",
      "Requirement already satisfied: narwhals>=1.17 in /opt/anaconda3/envs/nlp/lib/python3.9/site-packages (from formulaic>=0.2.2->lifelines) (1.31.0)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /opt/anaconda3/envs/nlp/lib/python3.9/site-packages (from formulaic>=0.2.2->lifelines) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.0 in /opt/anaconda3/envs/nlp/lib/python3.9/site-packages (from formulaic>=0.2.2->lifelines) (1.14.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/anaconda3/envs/nlp/lib/python3.9/site-packages (from matplotlib>=3.0->lifelines) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/anaconda3/envs/nlp/lib/python3.9/site-packages (from matplotlib>=3.0->lifelines) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/anaconda3/envs/nlp/lib/python3.9/site-packages (from matplotlib>=3.0->lifelines) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/anaconda3/envs/nlp/lib/python3.9/site-packages (from matplotlib>=3.0->lifelines) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/envs/nlp/lib/python3.9/site-packages (from matplotlib>=3.0->lifelines) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in /opt/anaconda3/envs/nlp/lib/python3.9/site-packages (from matplotlib>=3.0->lifelines) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/anaconda3/envs/nlp/lib/python3.9/site-packages (from matplotlib>=3.0->lifelines) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/anaconda3/envs/nlp/lib/python3.9/site-packages (from matplotlib>=3.0->lifelines) (2.9.0.post0)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /opt/anaconda3/envs/nlp/lib/python3.9/site-packages (from matplotlib>=3.0->lifelines) (6.4.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/envs/nlp/lib/python3.9/site-packages (from pandas>=2.1->lifelines) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/envs/nlp/lib/python3.9/site-packages (from pandas>=2.1->lifelines) (2025.1)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /opt/anaconda3/envs/nlp/lib/python3.9/site-packages (from importlib-resources>=3.2.0->matplotlib>=3.0->lifelines) (3.21.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/envs/nlp/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib>=3.0->lifelines) (1.16.0)\n",
      "Requirement already satisfied: scikit-survival in /opt/anaconda3/envs/nlp/lib/python3.9/site-packages (0.23.1)\n",
      "Requirement already satisfied: ecos in /opt/anaconda3/envs/nlp/lib/python3.9/site-packages (from scikit-survival) (2.0.14)\n",
      "Requirement already satisfied: joblib in /opt/anaconda3/envs/nlp/lib/python3.9/site-packages (from scikit-survival) (1.4.2)\n",
      "Requirement already satisfied: numexpr in /opt/anaconda3/envs/nlp/lib/python3.9/site-packages (from scikit-survival) (2.10.1)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/envs/nlp/lib/python3.9/site-packages (from scikit-survival) (1.26.4)\n",
      "Requirement already satisfied: osqp!=0.6.0,!=0.6.1 in /opt/anaconda3/envs/nlp/lib/python3.9/site-packages (from scikit-survival) (1.0.4)\n",
      "Requirement already satisfied: pandas>=1.4.0 in /opt/anaconda3/envs/nlp/lib/python3.9/site-packages (from scikit-survival) (2.2.3)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /opt/anaconda3/envs/nlp/lib/python3.9/site-packages (from scikit-survival) (1.13.1)\n",
      "Requirement already satisfied: scikit-learn<1.6,>=1.4.0 in /opt/anaconda3/envs/nlp/lib/python3.9/site-packages (from scikit-survival) (1.5.2)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/envs/nlp/lib/python3.9/site-packages (from osqp!=0.6.0,!=0.6.1->scikit-survival) (3.1.6)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/envs/nlp/lib/python3.9/site-packages (from osqp!=0.6.0,!=0.6.1->scikit-survival) (75.8.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/envs/nlp/lib/python3.9/site-packages (from pandas>=1.4.0->scikit-survival) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/envs/nlp/lib/python3.9/site-packages (from pandas>=1.4.0->scikit-survival) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/envs/nlp/lib/python3.9/site-packages (from pandas>=1.4.0->scikit-survival) (2025.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/anaconda3/envs/nlp/lib/python3.9/site-packages (from scikit-learn<1.6,>=1.4.0->scikit-survival) (3.5.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/envs/nlp/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas>=1.4.0->scikit-survival) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/envs/nlp/lib/python3.9/site-packages (from jinja2->osqp!=0.6.0,!=0.6.1->scikit-survival) (3.0.2)\n"
     ]
    }
   ],
   "source": [
    "# ! pip install lifelines\n",
    "# ! pip install scikit-survival"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bec59d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from lifelines.utils import concordance_index\n",
    "from sksurv.metrics import integrated_brier_score\n",
    "from sksurv.util import Surv\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "\n",
    "import modules.DataAnalysis as DataAnalysis\n",
    "import modules.ModelAnalysis as ModelAnalysis\n",
    "import modules.DataModify as DataModify\n",
    "from modules.DataSelect import DataPreprocessing\n",
    "\n",
    "import modules.Models as Models\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa6d346",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_deephit(model, test_loader, y_train, y_test, device='cuda', threshold=0.9):\n",
    "    \"\"\"\n",
    "    DeepHit 모델 평가 함수\n",
    "    - C-index\n",
    "    - Integrated Brier Score (IBS)\n",
    "    - 예측 시간 평균 오차 (MAE)\n",
    "    \n",
    "    마지막 시간 bin은 dummy이므로 제거 후 계산\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    all_risk = []\n",
    "    all_surv = []\n",
    "    all_times = []\n",
    "    all_events = []\n",
    "\n",
    "    pred_times_list = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, times, events in test_loader:\n",
    "            x = x.to(device)\n",
    "            _, pmf, cif = model(x)  # pmf, cif 반환 (B, num_events, time_bins)\n",
    "\n",
    "            # -----------------------------\n",
    "            # 마지막 더미 시간 bin 제거\n",
    "            # -----------------------------\n",
    "            pmf = pmf[:, :, :-1]       # (B, num_events, time_bins-1)\n",
    "            cif = cif[:, :, :-1]\n",
    "            survival = 1 - cif.sum(dim=1)  # (B, time_bins-1)\n",
    "\n",
    "            # -----------------------------\n",
    "            # Risk score 계산\n",
    "            # -----------------------------\n",
    "            risk_score = pmf.sum(dim=(1, 2))  # (B,)\n",
    "\n",
    "            all_risk.append(risk_score.cpu())\n",
    "            all_surv.append(survival.cpu())\n",
    "            all_times.append(times.cpu())\n",
    "            all_events.append(events.cpu())\n",
    "\n",
    "            # -----------------------------\n",
    "            # 예측 시간 계산\n",
    "            # -----------------------------\n",
    "            pmf_np = pmf.cpu().numpy()  # (B, num_events, time_bins)\n",
    "            batch_size, num_events, time_bins = pmf_np.shape\n",
    "\n",
    "            for i in range(batch_size):\n",
    "                surv_prob = 1.0\n",
    "                pred_time = None\n",
    "                for t in range(time_bins):\n",
    "                    surv_prob *= (1 - pmf_np[i, :, t].sum())\n",
    "                    if surv_prob <= threshold and pred_time is None:\n",
    "                        pred_time = t\n",
    "                if pred_time is None:\n",
    "                    pred_time = time_bins - 1\n",
    "                pred_times_list.append(pred_time)\n",
    "\n",
    "    # -----------------------------\n",
    "    # Tensor → NumPy 변환\n",
    "    # -----------------------------\n",
    "    risk_score = torch.cat(all_risk).numpy()\n",
    "    survival = torch.cat(all_surv).numpy()\n",
    "    times = torch.cat(all_times).numpy()\n",
    "    events = torch.cat(all_events).numpy()\n",
    "    pred_times = np.array(pred_times_list)\n",
    "\n",
    "    # -----------------------------\n",
    "    # Concordance Index 계산\n",
    "    # -----------------------------\n",
    "    c_index = concordance_index(\n",
    "        event_times=times,\n",
    "        predicted_scores=-risk_score,\n",
    "        event_observed=events\n",
    "    )\n",
    "\n",
    "    # -----------------------------\n",
    "    # Integrated Brier Score 계산\n",
    "    # -----------------------------\n",
    "    y_test_surv = Surv.from_arrays(\n",
    "        event=events.astype(bool),\n",
    "        time=times.astype(float)\n",
    "    )\n",
    "    max_time = int(y_test_surv[\"time\"].max())\n",
    "    survival = survival[:, :max_time]\n",
    "    eval_times = np.arange(max_time)\n",
    "    ibs = integrated_brier_score(y_train, y_test_surv, survival, eval_times)\n",
    "\n",
    "    # -----------------------------\n",
    "    # 평균 절대 예측 시간 오차 (MAE) 계산\n",
    "    # -----------------------------\n",
    "    mae = np.mean(np.abs(pred_times - times))\n",
    "\n",
    "    # -----------------------------\n",
    "    # 결과 출력\n",
    "    # -----------------------------\n",
    "    print(f\"Concordance Index (C-index): {c_index:.4f}\")\n",
    "    print(f\"Integrated Brier Score (IBS): {ibs:.4f}\")\n",
    "    print(f\"Mean Absolute Error (MAE) of predicted time: {mae:.4f}\")\n",
    "\n",
    "    return c_index, ibs, mae, pred_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f8ee9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 경로 지정\n",
    "# CSV 읽기 + 첫 열 제거\n",
    "df = pd.read_csv('./data/test dataset.csv')\n",
    "df = df.drop(df.columns[0], axis=1)  # 첫 열 제거\n",
    "df.to_csv('./data/test dataset_fixed.csv', index=False)\n",
    "\n",
    "# Dataset 로드\n",
    "test_file = ['./data/test dataset_fixed.csv']\n",
    "test_dataset = DataModify.CancerDataset(\n",
    "    target_column='event',\n",
    "    time_column='time',\n",
    "    file_paths=test_file\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# IBS 계산용 Surv 형식 생성\n",
    "test_times = test_dataset.time.numpy()\n",
    "test_events = test_dataset.target.numpy()\n",
    "\n",
    "# y_test만 있으면 IBS 계산 시 train은 동일 형식 dummy로 전달 가능\n",
    "y_test = Surv.from_arrays(event=test_events.astype(bool),\n",
    "                          time=test_times.astype(float))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd41b0d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeepHitSurvWithSEBlockAnd2DCNN(\n",
       "  (se_block): Sequential(\n",
       "    (0): Linear(in_features=17, out_features=4, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=4, out_features=17, bias=True)\n",
       "    (3): Sigmoid()\n",
       "  )\n",
       "  (se_block_event): ModuleList(\n",
       "    (0-3): 4 x Sequential(\n",
       "      (0): Linear(in_features=64, out_features=16, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=16, out_features=64, bias=True)\n",
       "      (3): Sigmoid()\n",
       "    )\n",
       "  )\n",
       "  (shared): Sequential(\n",
       "    (0): Linear(in_features=17, out_features=128, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.2, inplace=False)\n",
       "    (3): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (4): ReLU()\n",
       "    (5): Dropout(p=0.2, inplace=False)\n",
       "  )\n",
       "  (heads): ModuleList(\n",
       "    (0-3): 4 x Linear(in_features=64, out_features=91, bias=True)\n",
       "  )\n",
       "  (conv2d_block): Sequential(\n",
       "    (0): Conv2d(1, 8, kernel_size=(2, 5), stride=(1, 1), padding=(1, 2))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(8, 16, kernel_size=(2, 3), stride=(1, 1), padding=(0, 1))\n",
       "    (3): ReLU()\n",
       "    (4): Conv2d(16, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_params_path = './parameters/deephit_model_2D_CNN.pth'\n",
    "\n",
    "input_dim = 17   # input dimension : data의 feature의 개수\n",
    "hidden_size = (128, 64)             # 1번째, 2번째 hidden layer의 size\n",
    "time_bins = 91                     # 3개월 단위로 time을 split하여 각 구간으로 삼음 -> 270개월+ 는 하나로 취급\n",
    "num_events = 4                      # 사건의 개수\n",
    "\n",
    "# 모델 선언\n",
    "model = Models.DeepHitSurvWithSEBlockAnd2DCNN(input_dim, hidden_size, time_bins, num_events, dropout=.2).to(device)\n",
    "model.load_state_dict(torch.load(input_params_path, map_location=device))\n",
    "model.to(device)\n",
    "model.eval()  # 평가 모드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b57847",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concordance Index (C-index): 0.8263\n",
      "Integrated Brier Score (IBS): 0.2005\n"
     ]
    }
   ],
   "source": [
    "y_train_dummy = y_test.copy()\n",
    "\n",
    "# 평가 실행\n",
    "c_index, ibs, mae, _ = evaluate_deephit(model, test_loader, y_train_dummy, y_test, device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6fd15dce",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'ERR_IGNORE' from 'numpy.core.umath' (/opt/anaconda3/envs/nlp/lib/python3.9/site-packages/numpy/core/umath.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 64\u001b[0m\n\u001b[1;32m     61\u001b[0m risk_scores \u001b[38;5;241m=\u001b[39m compute_risk_score_sigmoid(pmf_train, time_lambda\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.05\u001b[39m, event_weights\u001b[38;5;241m=\u001b[39mevent_weights)\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m     63\u001b[0m \u001b[38;5;66;03m# 통계 확인\u001b[39;00m\n\u001b[0;32m---> 64\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m최대값:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrisk_scores\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m최소값:\u001b[39m\u001b[38;5;124m\"\u001b[39m, np\u001b[38;5;241m.\u001b[39mmin(risk_scores))\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m평균값:\u001b[39m\u001b[38;5;124m\"\u001b[39m, np\u001b[38;5;241m.\u001b[39mmean(risk_scores))\n",
      "File \u001b[0;32m/opt/anaconda3/envs/nlp/lib/python3.9/site-packages/numpy/_core/fromnumeric.py:2899\u001b[0m, in \u001b[0;36mmax\u001b[0;34m(a, axis, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   2781\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_max_dispatcher)\n\u001b[1;32m   2782\u001b[0m \u001b[38;5;129m@set_module\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumpy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m   2783\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmax\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39m_NoValue, initial\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39m_NoValue,\n\u001b[1;32m   2784\u001b[0m          where\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39m_NoValue):\n\u001b[1;32m   2785\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2786\u001b[0m \u001b[38;5;124;03m    Return the maximum of an array or maximum along an axis.\u001b[39;00m\n\u001b[1;32m   2787\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2897\u001b[0m \u001b[38;5;124;03m    5\u001b[39;00m\n\u001b[1;32m   2898\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2899\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapreduction\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmaximum\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmax\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2900\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/nlp/lib/python3.9/site-packages/numpy/_core/fromnumeric.py:84\u001b[0m, in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m reduction(axis\u001b[38;5;241m=\u001b[39maxis, dtype\u001b[38;5;241m=\u001b[39mdtype, out\u001b[38;5;241m=\u001b[39mout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpasskwargs)\n\u001b[1;32m     83\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 84\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mreduction\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpasskwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ufunc\u001b[38;5;241m.\u001b[39mreduce(obj, axis, dtype, out, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpasskwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/nlp/lib/python3.9/site-packages/numpy/core/_methods.py:14\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m numerictypes \u001b[38;5;28;01mas\u001b[39;00m nt\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _exceptions\n\u001b[0;32m---> 14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_ufunc_config\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _no_nep50_warning\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_globals\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _NoValue\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pickle, os_fspath\n",
      "File \u001b[0;32m/opt/anaconda3/envs/nlp/lib/python3.9/site-packages/numpy/core/_ufunc_config.py:11\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcontextvars\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m set_module\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mumath\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     12\u001b[0m     UFUNC_BUFSIZE_DEFAULT,\n\u001b[1;32m     13\u001b[0m     ERR_IGNORE, ERR_WARN, ERR_RAISE, ERR_CALL, ERR_PRINT, ERR_LOG, ERR_DEFAULT,\n\u001b[1;32m     14\u001b[0m     SHIFT_DIVIDEBYZERO, SHIFT_OVERFLOW, SHIFT_UNDERFLOW, SHIFT_INVALID,\n\u001b[1;32m     15\u001b[0m )\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m umath\n\u001b[1;32m     18\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseterr\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgeterr\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msetbufsize\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgetbufsize\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseterrcall\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgeterrcall\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merrstate\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_no_nep50_warning\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     21\u001b[0m ]\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'ERR_IGNORE' from 'numpy.core.umath' (/opt/anaconda3/envs/nlp/lib/python3.9/site-packages/numpy/core/umath.py)"
     ]
    }
   ],
   "source": [
    "def compute_risk_score_sigmoid(pmf, time_lambda=0.05, event_weights=None):\n",
    "    \"\"\"\n",
    "    pmf: torch.Tensor, shape (B, E, T) - 사건별 시간 확률\n",
    "    time_lambda: float, 지수 감쇠 계수 (시간대 가중치)\n",
    "    event_weights: list or torch.Tensor, 길이 E, 사건별 가중치\n",
    "    \"\"\"\n",
    "    B, E, T = pmf.shape\n",
    "    device = pmf.device\n",
    "\n",
    "    # 시간 가중치\n",
    "    time_weights = torch.exp(-time_lambda * torch.arange(T, device=device))\n",
    "    \n",
    "    # 사건 가중치\n",
    "    if event_weights is None:\n",
    "        event_weights = torch.ones(E, device=device)\n",
    "    else:\n",
    "        event_weights = torch.tensor(event_weights, device=device, dtype=torch.float32)\n",
    "    \n",
    "    # 가중치 적용\n",
    "    weighted_pmf = pmf * time_weights.view(1, 1, T)\n",
    "    weighted_pmf = weighted_pmf * event_weights.view(1, E, 1)\n",
    "\n",
    "    # 가중합 계산\n",
    "    risk_score_raw = weighted_pmf.sum(dim=(1, 2))\n",
    "\n",
    "    # 0 기준으로 offset 제거 → 음수도 나오게\n",
    "    risk_score_raw = risk_score_raw - risk_score_raw.mean()\n",
    "\n",
    "    # 시그모이드 + 0~100 스케일\n",
    "    risk_score = torch.sigmoid(risk_score_raw) * 100\n",
    "\n",
    "    return risk_score\n",
    "\n",
    "def get_pmf_from_model(model, loader, device=device):\n",
    "    model.eval()\n",
    "    all_pmf = []\n",
    "    all_times = []\n",
    "    all_events = []\n",
    "    with torch.no_grad():\n",
    "        for x, times, events in loader:\n",
    "            x = x.to(device)\n",
    "            logits, pmf, _ = model(x)  # CIF는 필요 없음\n",
    "\n",
    "            pmf = pmf[:, :, :91]  # (batch_size, num_events, time_bins-1)\n",
    "            \n",
    "            all_pmf.append(pmf.cpu())\n",
    "            all_times.append(times)\n",
    "            all_events.append(events)\n",
    "    all_pmf = torch.cat(all_pmf, dim=0)  # (num_samples, num_events, time_bins)\n",
    "    all_times = torch.cat(all_times, dim=0)\n",
    "    all_events = torch.cat(all_events, dim=0)\n",
    "    return all_pmf, all_times, all_events\n",
    " \n",
    "# train set PMF 추출\n",
    "pmf_train, times_train, events_train = get_pmf_from_model(model, test_loader)\n",
    "\n",
    "# 사건별 가중치 설정\n",
    "event_weights = [2.0, 3.0, 3.0, 15.0]  # 예시\n",
    "\n",
    "# 위험 점수 계산 (시그모이드 + 0~100)\n",
    "risk_scores = compute_risk_score_sigmoid(pmf_train, time_lambda=0.05, event_weights=event_weights).numpy()\n",
    "\n",
    "# 통계 확인\n",
    "print(\"최대값:\", np.max(risk_scores))\n",
    "print(\"최소값:\", np.min(risk_scores))\n",
    "print(\"평균값:\", np.mean(risk_scores))\n",
    "print(\"앞 10개 값:\", risk_scores[:10])\n",
    "\n",
    "# 사건별 통계\n",
    "events_np = events_train.numpy()\n",
    "unique_events = np.unique(events_np)\n",
    "\n",
    "print(\"=== 라벨별 Risk Score 통계 ===\")\n",
    "for e in unique_events:\n",
    "    mask = (events_np == e)\n",
    "    scores_e = risk_scores[mask]\n",
    "    if len(scores_e) == 0:\n",
    "        continue\n",
    "    print(f\"\\nEvent {e}:\")\n",
    "    print(f\"  개수: {len(scores_e)}\")\n",
    "    print(f\"  최대값: {np.max(scores_e):.4f}\")\n",
    "    print(f\"  최소값: {np.min(scores_e):.4f}\")\n",
    "    print(f\"  평균값: {np.mean(scores_e):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e532d58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
